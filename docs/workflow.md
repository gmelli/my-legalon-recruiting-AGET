# Recruiting Evaluation Workflow

## Quick Start

### 1. Add Candidate Resumes
Place resumes in:
- **Japan candidates**: `~/Downloads/resumes-JP/`
- **USA candidates**: `~/Downloads/resumes-US/`

Supported formats: PDF, DOCX, TXT

### 2. Request Evaluation
Tell the agent:
```
Evaluate candidates from resumes-JP for AI Engineer (Agents) role
```

Or provide specific details:
```
Process candidate in resumes-US/john-doe-resume.pdf
Role: Data Scientist (Product)
LinkedIn: [paste profile info]
```

### 3. Review Outputs
Evaluations saved to: `workspace/evaluations/`

Format: `{region}_{candidate-id}_evaluation_{YYYY-MM-DD}.md`

---

## Batch Processing

**Every ~5 days workflow**:
1. Drop multiple resumes into region folder
2. Request batch evaluation: "Evaluate all candidates in resumes-JP for AI Engineer (NLP)"
3. Agent processes each candidate sequentially
4. Review evaluations in `workspace/evaluations/`

**Outputs**:
- Individual assessments for each candidate
- Level fit (L3-L6 or DS1-DS4)
- Skills match against job description
- Strengths, gaps, recommendation

---

## Deep Dive Mode

**For advancing candidates**:
1. Candidate progresses through interviews
2. Provide feedback: "Candidate L interview feedback: [paste notes]"
3. Agent integrates feedback into existing evaluation
4. Request comparison: "Compare Candidate L vs other AI Engineer (Agents) candidates"

**Outputs**:
- Updated evaluation with interview notes
- Comparative analysis within role cohort
- Ranking and differentiation

---

## Available Roles

### Engineering
- **AI Engineer (Agents)** - Agentic systems, LLMs, orchestration
- **AI Engineer (NLP)** - Text processing, language models, linguistic analysis

### Data Science
- **Data Scientist (Product)** - Product analytics, A/B testing, metrics

---

## Data Storage

### Input (User manages)
- `~/Downloads/resumes-JP/` - Japan candidate materials
- `~/Downloads/resumes-US/` - USA candidate materials

### Processing (Agent manages, ⚠️ PII - gitignored)
- `data/candidates/japan/{candidate-id}/` - Raw materials storage
- `data/candidates/usa/{candidate-id}/` - Raw materials storage
- `workspace/evaluations/` - Generated assessments

### Framework (Committed to git)
- `data/job_descriptions/` - Role requirements
- `data/level_requirements/` - Level definitions (L3-L6, DS1-DS4)
- `docs/evaluation-template.md` - Assessment structure

---

## Privacy Controls

**Automatic protections**:
- `data/candidates/` - Gitignored (never committed)
- `workspace/evaluations/` - Gitignored (pattern: `*_evaluation_*.md`)
- Agent uses anonymized IDs in session notes (e.g., "Candidate A")
- PII audit step before saving evaluations

**Manual cleanup**:
- Delete `data/candidates/{region}/{candidate-id}/` when hiring round completes
- Archive or delete evaluations after decisions made
- No cloud sync for candidate directories (Dropbox/iCloud disabled)

---

## Commands Reference

### Batch evaluation
```
Evaluate all candidates in resumes-JP for [role]
Process resumes-US batch for Data Scientist
```

### Single candidate
```
Evaluate candidate at ~/Downloads/resumes-JP/resume.pdf
Role: AI Engineer (Agents)
LinkedIn: [info]
```

### Deep dive
```
Show evaluation for Candidate L
Add interview feedback for Candidate L: [notes]
Compare Candidate L vs other AI Engineer (Agents) candidates
```

### Comparison
```
Compare all AI Engineer (NLP) candidates
Rank Data Scientists by product sense
```

---

## Troubleshooting

**"No candidates found"**
- Check file path: `~/Downloads/resumes-JP/` exists?
- Verify file format: PDF, DOCX, TXT supported

**"Incomplete data"**
- Resume must have: name, experience, skills
- Provide LinkedIn info if resume is sparse

**"Evaluation has PII"**
- Agent auto-sanitizes, but double-check before sharing
- Use anonymized references in external communications

---

*Generated by my-legalon-recruiting-AGET v2.5.1*
*Last updated: 2025-10-06*
